
> Q550 Homework 3: Perceptrons (Non-Linear, Single-Layer Networks)
> 
> **** KEY ****
> 
> Rules and Exceptions in Perceptrons.  As an introduction to this
> exercise, look at Q.4.4.1-Q.4.4.4 in PDP~III.  Study them, look at the
> answers in the back of the book, but don't turn in any answers to
> those questions.
> 
> Now do the following: First, get the pattern file 78.pat and ptrain
> the network for 200 epochs. (Set the stepsize to nepoch, and set
> nepoch to 200, so that you aren't slowed down terribly by screen
> updates.) Save the screen so you later can examine the resulting
> weight matrix.  Second, reset the network, and get the pattern file
> all.pat, and ptrain for 200 epochs.  Save the screen.  Third, copy the
> 78.pat file to a new file and in the new file change BOTH the 147 and
> 148 patterns to exceptions, so that 147=>147 and 148=>148. Reset the
> network, get the new pattern file, and ptrain for 200 epochs.  Save
> the resulting screen.
> 
> A. In your homework, turn in printouts of the three screens.

**** 10 pts. ****

===== NO EXCEPTIONS (78.pat) =====

pa:  save scr hw1scr1.txt                                                      
disp/  exam/  get/  save/  set/  clear  do  log  newstart  ptrain  quit  reset 
run  strain  tall  test                                                        
                                                                               
                                                                               
epochn    200                                      pname ipattern  tpattern    
cpname   p368                                      p147  10010010  10010001    
pss    0.0000                                      p148  10010001  10010010    
tss    2.0000                                      p157  10001010  10001001    
                                                   p158  10001001  10001010    
weights                               out   tar    p167  10000110  10000101    
                                                   p168  10000101  10000110    
           98-62-56-10 -6 -4-12 -8     0     0     p247  01010010  01010001    
          -60 96-62 -6-10-10-14-12     0     0     p248  01010001  01010010    
          -62-58 96 -6-10 -8-12-12     1     1     p257  01001010  01001001    
          -10-10  0102-68-54-12 -8     0     0     p258  01001001  01001010    
          -12-12 -6-66 96-60 -8-22     0     0     p267  01000110  01000101    
           -8 -6-10-58-58 92-16 -8     1     1     p268  01000101  01000110    
            2 -4  0  4 -4 -2-84 82     1     1     p347  00110010  00110001    
            0  0 -4 -6  2  0 80-84     0     0     p348  00110001  00110010    
                                                   p357  00101010  00101001    
input       0  0  1  0  0  1  0  1                 p358  00101001  00101010    
                                                   p367  00100110  00100101    

===== ONE EXCEPTION (all.pat) =====

pa:  save scr hw4scr2.txt                                                      
disp/  exam/  get/  save/  set/  clear  do  log  newstart  ptrain  quit  reset 
run  strain  tall  test                                                        
                                                                               
                                                                               
epochn    200                                      pname ipattern  tpattern    
cpname   p368                                      p147  10010010  10010010    
pss    0.0000                                      p148  10010001  10010010    
tss    2.0000                                      p157  10001010  10001001    
                                                   p158  10001001  10001010    
weights                               out   tar    p167  10000110  10000101    
                                                   p168  10000101  10000110    
           98-62-56-10 -6 -4-12 -8     0     0     p247  01010010  01010001    
          -60 96-62 -6-10-10-14-12     0     0     p248  01010001  01010010    
          -62-58 96 -6-10 -8-12-12     1     1     p257  01001010  01001001    
          -10-10  0102-68-54-12 -8     0     0     p258  01001001  01001010    
          -12-12 -6-66 96-60 -8-22     0     0     p267  01000110  01000101    
           -8 -6-10-58-58 92-16 -8     1     1     p268  01000101  01000110    
           54-20-18 52-18-18-76 92     1     1     p347  00110010  00110001    
          -52 14 22-54 22 16 84-99     0     0     p348  00110001  00110010    
                                                   p357  00101010  00101001    
input       0  0  1  0  0  1  0  1                 p358  00101001  00101010    
                                                   p367  00100110  00100101    

===== TWO EXCEPTIONS (78both.pat) =====

pa:  save scr hw4scr3.txt                                                      
disp/  exam/  get/  save/  set/  clear  do  log  newstart  ptrain  quit  reset 
run  strain  tall  test                                                        
                                                                               
                                                                               
epochn    200                                      pname ipattern  tpattern    
cpname   p368                                      p147  10010010  10010010    
pss    0.0000                                      p148  10010001  10010001    
tss    8.0000                                      p157  10001010  10001001    
                                                   p158  10001001  10001010    
weights                               out   tar    p167  10000110  10000101    
                                                   p168  10000101  10000110    
           98-62-56-10 -6 -4-12 -8     0     0     p247  01010010  01010001    
          -60 96-62 -6-10-10-14-12     0     0     p248  01010001  01010010    
          -62-58 96 -6-10 -8-12-12     1     1     p257  01001010  01001001    
          -10-10  0102-68-54-12 -8     0     0     p258  01001001  01001010    
          -12-12 -6-66 96-60 -8-22     0     0     p267  01000110  01000101    
           -8 -6-10-58-58 92-16 -8     1     1     p268  01000101  01000110    
            8  0 -6  0  0  2-30 32     1     1     p347  00110010  00110001    
            2 -4  2  2  0 -2 34-34     0     0     p348  00110001  00110010    
                                                   p357  00101010  00101001    
input       0  0  1  0  0  1  0  1                 p358  00101001  00101010    
                                                   p367  00100110  00100101    
=======================================

> B. Did the network learn the rule with one exception? (Careful! This
> is a stochastic network, so you can't judge by outputs from a single
> test trial.  You must instead examine the weights!)  

**** 10 pts ****

Yes, it did learn the exception.  To see that, we must examine the
weights in the 7th and 8th row:

           54-20-18 52-18-18-76 92
          -52 14 22-54 22 16 84-99 

For the 7th output node, the net input for pattern 147 is
.54+.52-.76=.30, which is positive, so that the 7th output node tends
to be on.  For the 8th output node, the net input for pattern 147 is
-.52-.54+.84=-.22, which is negative, so that the 8th output node
tends to be off.

(That's all I intended for that part of the exercise, but to be
thorough, one could also show that the network tends to be correct for
all the other [regular] training cases too!  That can be done with
brute force, by going through every pattern, or it can be done by
pointing out that no combination of two weights other than the 1st and
4th can overcome the magnitude of the 7th weight.)

> Explain how the weights are different in the one-exception case than
> in the no-exception case so that the exception could be
> accommodated. (Don't just point out the different weights; explain
> what difference they make for getting the exception correct.)

**** 5 pts ****

In the no-exception case, the weights to the 7th and 8th nodes are as
follows:

            2 -4  0  4 -4 -2-84 82
            0  0 -4 -6  2  0 80-84

Essentially, the weights from input nodes 1-6 are zero, and the
weights from the 7th and 8th input nodes act as "inverters," just
exchanging the values of nodes 7 and 8.

The weights for the one-exception set maintain the "inverters," but
also develop non-zero weights from input nodes 1-6.  In particular,
the weights from input nodes 1 and 4 are large enough to overcome the
"inverters", but no other combination of two weights from nodes 1-6 is
large enough.

> C. Did the network learn the two-exception case?  

**** 5 pts ****

No, it did not learn the two exceptions.  To demonstrate that, we must
examine the weights to the 7th and 8th nodes:

            8  0 -6  0  0  2-30 32
            2 -4  2  2  0 -2 34-34

For input 147, the net input of the 7th output node is
.08+.0-.30=-.22, which is negative, not positive as required.

For input 148, the net input of the 7th output node is
.08+.0+.32=.40, which is positive, not negative as required.

> Why or why not?  

**** 5 pts ****

The two patterns put opposite demands on the weights from the 1st and
4th input nodes.  For 147, the 1st and 4th weights need to be positive
enough to overcome the negative weight from the 7th node.  But, for
148, the 1st and 4th weights need to be negative enough to overcome
the positive weight from the 8th node.

> How are the weights different from the no-exception case?  Why?

**** 5 pts ****

The weights from input nodes 1-6 are similar, all nearly zero, but the
weights from nodes 7 and 8 not as large for the two-exception set as
for the no-exception set.  The 1-6 weights are nearly zero because of
the conflicting demands described in the previous part --- the demands
to increase weights cancel the demands to decrease weight.  The 7-8
weights are lower magnitude because there is a smaller proportion of
regular cases, and no other weights 1-6 to accommodate the exceptions.
So, the 7-8 weights bear the full burden of accommodating the
exceptions as best they can.

> D. Could the network learn some OTHER two-exception case?  Could it
> learn a three-exception case?  (The answers are yes and yes.) Think of
> examples of such cases.  

**** 5 pts ****

Here are examples of two-exception and four-exception sets.  The
exceptions are marked in the list of patterns with an "E" as the first
letter in their "pname."

==== two-exception set ====
                                                                               
epochn    200                                      pname ipattern  tpattern    
cpname   p167                                      E147  10010010  10010010    
pss    1.0000                                      p148  10010001  10010010    
tss    2.0000                                      E157  10001010  10001010    
                                                   p158  10001001  10001010    
weights                               out   tar    p167  10000110  10000101    
                                                   p168  10000101  10000110    
           92-58-62-14 -4-10-14-14     1     1     p247  01010010  01010001    
          -62 94-58 -6-10-10-12-14     0     0     p248  01010001  01010010    
          -62-68 98-10-10-12-18-14     0     0     p257  01001010  01001001    
           -6-16 -8 96-58-68-14-16     0     0     p258  01001001  01001010    
           -8-14 -6-60 92-60-14-14     0     0     p267  01000110  01000101    
          -14 -8 -4-62-62 98-12-14     1     1     p268  01000101  01000110    
           64-18-16 34 32-36-70100     1     0     p347  00110010  00110001    
          -74 16 24-36-32 34 72-99     1     1     p348  00110001  00110010    
                                                   p357  00101010  00101001    
input       1  0  0  0  0  1  1  0                 p358  00101001  00101010    
                                                   p367  00100110  00100101    

==== four-exception set ====
                                                                               
epochn    200                                      pname ipattern  tpattern    
cpname   p167                                      E147  10010010  10010010    
pss    1.0000                                      p148  10010001  10010010    
tss    3.0000                                      E157  10001010  10001010    
                                                   p158  10001001  10001010    
weights                               out   tar    p167  10000110  10000101    
                                                   p168  10000101  10000110    
           92-58-62-14 -4-10-14-14     1     1     E247  01010010  01010010    
          -62 94-58 -6-10-10-12-14     0     0     p248  01010001  01010010    
          -62-68 98-10-10-12-18-14     0     0     E257  01001010  01001010    
           -6-16 -8 96-58-68-14-16     0     0     p258  01001001  01001010    
           -8-14 -6-60 92-60-14-14     0     0     p267  01000110  01000101    
          -14 -8 -4-62-62 98-12-14     1     1     p268  01000101  01000110    
           44 50-36 54 42-38-52110     1     0     p347  00110010  00110001    
          -52-50 38-52-54 42 54-99     1     1     p348  00110001  00110010    
                                                   p357  00101010  00101001    
input       1  0  0  0  0  1  1  0                 p358  00101001  00101010    
                                                   p367  00100110  00100101    
================

> E. Why is it that some exceptions can be accommodated, but others
> cannot be?  (Just a simple answer suffices, here.  You might be
> repeating yourself from previous answers.)

**** 5 pts ****

The exceptions in the examples above did not put conflicting
constraints on the weights.  For example, 147=>147 and 157=>157 both
require the weight from the 1st input node to be large enough (in
combination with the weight from the 4th or 5th node) to overcome the
negative weight from the seventh node.

In general, that means that the exceptions and the regulars must be
*linearly separable* in input space.  Imagine that you are the 7th
output node.  Your job is to look down on the 8-dimensional input
space and (usually) turn on whenever input node 7 is off and 8 is on,
and (usually) turn off whenever input node 7 is on and 8 is off.
That's a simple linear slice through the 7/8 input dimensions.  Any
exceptions must tilt that slice through the other input dimensions,
maintaining all the "on" patterns on one side of the slice, and all
the "off" patterns on the other.

==============

MORAL: (Not asked for...)  The moral of this exercise is that
perceptrons make no distinction between "regular" and "exceptional"
patterns.  As far as the network is concerned, all the patterns have
equal status, and the network simply tries to accommodate them all
equally as best it can.  The only thing a perceptron "knows" is linear
distinctions in input space, which may or may not map onto the
human programmer's sense of "rules."

> ===end===
