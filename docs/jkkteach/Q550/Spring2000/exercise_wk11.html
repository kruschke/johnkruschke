<HTML>
<HEAD>
<TITLE>Q550 Models in Cognitive Science, Prof. Kruschke</TITLE>
</HEAD>
<BODY bgcolor="#FFFFFF">

<center>
<h3> 
<a href="http://www.indiana.edu/~jkkteach/Q550/">
Q550 Models in Cognitive Science</a>,
<a href="http://www.indiana.edu/~kruschke/">Prof. John K. Kruschke</a>
</h3>
<h2>
Exercises, Week 11, Due Tuesday 4 April 2000.
</h2>
</center>


<p> "MPnR Reading" refers to the book by McLeod, Plunkett and
Rolls.


<ul>

<li>Consider the Seidenberg and McClelland model, pp. 158-167.  List
all the free parameters of the model.  In constructing your list,
consider implicit free parameters in the input/output representation,
the architecture, the processing, the training, the function that
converts error to latency, etc.

<!-- ------------------------------------------------------------------

<li>In the <tt>tlearn</tt> simulation of Plaut et al. (pp. 172-177),
test the trained network's ability to pronounce the following words:

<center>
<table border=1>
<tr><td>DIN</td><td>DINT</td><td>DINE</td></tr>
<tr><td>PIN</td><td>PINT*</td><td>PINE</td></tr>
<tr><td>FIN</td><td>FINT**</td><td>FINE</td></tr>
<tr><td>GIN*</td><td>GINT**</td><td>GINE**</td></tr>
<tr><td>GIF***</td><td>GIFT</td><td>GIFE**</td></tr>
<tr><td colspan=3>* = irregular, ** = pronouncable nonword
<br>*** = nonword except for computer jargon</td></tr>
</table>
</center>

Show printouts of the network's predictions. Use the translation
utility.  Does the network prounounce all the real words correctly?
Does the network pronounce the "I" in FINT, GINT, GINE and GIFE
regularly or irregularly or as something completely different?  Does
the network pronounce the "G" in the six G... words as hard (as in
GIFT) or soft (as in GERM) or as something completely different?

<li>In the <tt>tlearn</tt> simulation of Plaut et al. (pp. 172-177),
test for word-frequency effects, like those shown in Figure 8.3.  Use
the words MUST, MODE, HAVE and LOSE as representative instances, and
plot the mean squared error (MSE) of the four words like the graph of
Figure 8.3.  Does the simulation show the same interaction as Figure
8.3?  Why or why not?

---------------------------------------------------------------- -->


<p><li>Regarding the past tense network (pp. 202-209): [Don't try doing
the generalization part of the exercise on p.209, because it just
crashes the program.]  Increase the number of hidden nodes from 20 to
50, and train the network.  Show a printout of the network
architecture, using "slabs," "labels," "arrows" and "bias."  Show a
printout of the plot of the MSE during the 25,000 sweeps of training,
and show a plot of the error when subsequently tested on the 500
training patterns.  Does this expanded network learn the two arbitrary
verbs and 68 vowel change verbs any better than the original (smaller)
network?  Answer this question by comparing the error plot with Figure
9.12, for each of the four types of verbs listed on p. 203.

</ul>

<p>For fun: <a href="pronunciation.html">some examples of English
pronunciation.</a>

<p><hr>

</BODY>
</HTML>


