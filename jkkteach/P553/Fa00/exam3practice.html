<HTML>
<HEAD>
<TITLE>P553 Statistics in Psychology, Prof. Kruschke</TITLE>
</HEAD>
<BODY bgcolor="FFFFFF">

<center>
<h2>
<a href="http://www.indiana.edu/~jkkteach/P553/">
P553 Statistics in Psychology</a>, 
<a href="http://www.indiana.edu/~kruschke/">Prof. Kruschke</a>
<p>Practice Exam 3
</h2>
</center>


<p> The exam will not be this long, but it will have problems like
these.  <em>You are encouraged to discuss these questions, and even
post answers or candidate answers, on the <a
href="http://www.indiana.edu/~jkkteach/p553_bbs/p553.cgi">Discussion
web page</a>.</em> Do not turn in answers to these problems.  This is
not a homework assignment.  There is no homework assignment this week,
other than doing these problems for your own review.

<p>For some of these exercises, you might need to use the Tables of
<em>z</em>, <em>t</em>, <em>q</em>, <em>F</em>, <em>power</em>,
<em>chi-square</em>, etc., in the Appendices of the textbook.  Copies
of these tables will be supplied during the exam.

<ol>


<p><li>Determine <em>how</em> you would answer Exercises 1, 2, 5, 8,
10, 12, 13 and 14 from pages 578-586 in the textbook.  That is, given
the design, you should know what sort of analysis is appropriate.  You
should also be able to analyze these sorts of problems for the exam,
but data sets on exam problems will be much smaller.

<p><li>Suppose we have 5 individuals, from whom we've measured two
interval-scale attributes, as follows:

<table cellpadding=1>
<tr><td>individual</td><td>score 1</td><td>score 2</td></tr>
<tr><td> 1 </td><td> 13 </td><td> 47 </td></tr>
<tr><td> 2 </td><td> 15 </td><td> 49 </td></tr>
<tr><td> 3 </td><td> 17 </td><td> 50 </td></tr>
<tr><td> 4 </td><td> 14 </td><td> 46 </td></tr>
<tr><td> 5 </td><td> 16 </td><td> 48 </td></tr>
</table>

<ul>

<li>Convert the scores to standardized values.

<li>Compute the correlation of score 1 with score 2, using the definition
of correlation.

<li>Determine whether the correlation is significantly different from
zero.  What assumptions have you made in this test?

</ul>


<p><li>Suppose we have 6 individuals, from whom we've measured two
attributes, as follows:

<table cellpadding=1>
<tr><td>individual</td><td>group</td><td>score</td></tr>
<tr><td> 1 </td><td> 1 </td><td> 46 </td></tr>
<tr><td> 2 </td><td> 1 </td><td> 47 </td></tr>
<tr><td> 3 </td><td> 1 </td><td> 48 </td></tr>
<tr><td> 4 </td><td> 2 </td><td> 48 </td></tr>
<tr><td> 5 </td><td> 2 </td><td> 50 </td></tr>
<tr><td> 6 </td><td> 2 </td><td> 52 </td></tr>
</table>

<ul>

<li>Write the equation of the linear regression model for these data.

<li>When regressing the score onto the group, what is the slope and
intercept of the best fitting regression line?  (You should be able to
do this in your head; no pencil, paper or computer required.)

</ul>


<p><li>Do an ANOVA on the data in the previous problem.  What are the
assumptions of this analysis?  Write the equation of the model being fit.


<p><li>In ANOVA, we are testing for differences between means.  So why
is it called analysis of <em>variance</em>?

<p><li>In ANOVA, why is it that, under the null hypothesis, the
expected value of F is 1.0?

<p><li>What is the difference between Tukey's HSD and Fisher's LSD?

<p><li>Suppose we have 2 independent groups with 4 scores each:

<table cellpadding=1>
<tr><td>group</td><td>score</td></tr>
<tr><td> 1 </td><td> 1.000 </td></tr>
<tr><td> 1 </td><td> 2.744 </td></tr>
<tr><td> 1 </td><td> 4.096 </td></tr>
<tr><td> 1 </td><td> 8.000 </td></tr>
<tr><td> 2 </td><td> 125.000 </td></tr>
<tr><td> 2 </td><td> 157.464 </td></tr>
<tr><td> 2 </td><td> 175.616 </td></tr>
<tr><td> 2 </td><td> 216.000 </td></tr>
</table>

<ul>

<li>Consider conducting a t-test of the data.  What assumptions would
you be making?  Do the data appear to satisfy these assumptions?

<li>Which of the following data transformations is most likely to
result in the data better satisfying the assumptions of the t-test?
<br>exp(x)
<br>x<sup>2</sup>
<br>sin(x)
<br>x<sup>1/3</sup>

<li>If, instead of transforming the data, you were to conduct a
randomization test, how many differences of means would you have to
compute?  Would the difference between the groups be significant in
this case? (Assume a two-tailed test, with a significance level of
.05.)

</ul>

<p><li>Suppose we have 2 independent groups with 4 scores each:

<table cellpadding=1>
<tr><td>group</td><td>score</td></tr>
<tr><td> 1 </td><td> 1.000 </td></tr>
<tr><td> 1 </td><td> 2.744 </td></tr>
<tr><td> 1 </td><td> 175.616 </td></tr>
<tr><td> 1 </td><td> 216.000 </td></tr>
<tr><td> 2 </td><td> 4.096 </td></tr>
<tr><td> 2 </td><td> 8.000 </td></tr>
<tr><td> 2 </td><td> 125.000 </td></tr>
<tr><td> 2 </td><td> 157.464 </td></tr>
</table>

<ul>

<li>Consider conducting a t-test of the data.  What assumptions would
you be making?  Do the data appear to satisfy these assumptions?

<li>Which, if any, of the following data transformations will result
in the data better satisfying the assumptions of the t-test?
<br>exp(x)
<br>x<sup>2</sup>
<br>sin(x)
<br>x<sup>1/3</sup>

<li>If, instead of transforming the data, you were to conduct a
randomization test, how many differences of means would you have to
compute?  Would the difference between the groups be significant in
this case? (Assume a two-tailed test, with a significance level of
.05.)

</ul>

<p><li>Why, when conducting a chi-square test, must the expected value
in each cell be not too extreme?

<p><li>Define the continuous chi-square distribution.

<p><li>For a chi-square test of independence, an R-row by C-column
table has (R-1)(C-1) degrees of freedom.  Why?

<p><li>You're a reviewer for manuscripts submitted to the <em>Journal
of Extraordinary Results, Knowledge, and Sagacity</em> (JERKS).  The
following passages appear in manuscripts you review.  Find the errors.

<ul>

<li>There were 15 subjects in each of 3 groups. An omnibus ANOVA
revealed a significant difference between groups, F(1,12)=1.54, p<.05
two-tailed.

<li>Of the 20 different categorical outcomes, our sample of 20 subjects
showed a preference for just 2 categories, t(19)=300.4, p<.001, 

<li>We compared each of the seven treatment conditions against the
control condition, and three of them were significantly different from
the control, with comparisons yielding t-statistics as follows (in
order): t(10)=2.24, p<.05; t(10)= 2.24, p<.05; t(10)=2.23, p<.05;
t(10)=2.20, p>.05; t(10)=2.19, p>.05.

<li>Subjects were assigned randomly to the three groups by the
experimenter interviewing the subject and then thinking of a number
between 1 and 3.  The results confirmed our theory's prediction, with
a significant difference between groups, F(2,2)=47,000.01, p<0.

<li>In it, an almost preternatural insight into the significance of
intelligible form is fused with a lyrical sensuality which prevents
stylization from becoming academic and lifeless, the mere repetition
of formula (t(1)=9.5, p<.05).

<li>Contrary to the prediction made by our competitor's feeble attempt
of a theory, the two conditions did not differ, t(4)=2.75, p>.05.

<li>Of 12 statistics exercises, only 1 was funny.  Therefore we cannot
reject the null hypothesis that the humor was merely accidental and
occurred by random chance (assuming a background random humor
probability of p=.083), z=0, p=.5.  (Okay, I'll give you the answer to
this one.  The error is in the author's assumption about the
background random humor level.  In fact, it's much closer to .99.
Therefore, the authors should have concluded that the statistics
exercises were much less funny than expected by chance...)

</ul>

<p><hr>

</BODY>
</HTML>


