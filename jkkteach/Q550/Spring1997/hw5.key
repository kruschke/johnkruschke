
KEY:  Q550 Homework 5: Simple Recurrent Networks (SRN's).

> 1A. During training, when the input is 0 and the teacher is 0 or 1,
> do the weights from the input nodes change? Why not?  Do the weights
> from the context nodes change? Why?  Do the weights from the hidden
> nodes change? Why?  When the teacher is -1 ("don't care"), do any of
> the weights change? Why not?

5 pts.

In an SRN, the training takes place by backpropagation of error, i.e.,
it is error-driven.  Formally:

  change in w(k,i) = lrate * delta(k) * act(i).  
 
When the teacher is "don't care," there will be no error (delta), and
so none of the weights changes.

When the teacher is 0 or 1, there usually will be significant error
(at least early in training), and so weights can change if their
source-node activation is non-zero.  Thus, when the input pattern is
1, the input-to-hidden weights will change, but not when the input
pattern is 0.  The context-to-hidden weights will change because the
context node activations will usually be non-zero, and the
hidden-to-output weights will change because the hidden node
activations will usually be non-zero.


> 1B. How is it possible for the network to learn both pattern 00 and
> 01?  After all, they have the same inputs but different outputs.

5 pts.

Whereas the two patterns have the same input, they have different
temporal contexts, and that difference is represented by the the
context node activations.


> 1C. Does the output value for the pattern 0_ anticipate its next
> output value?  In what way?  Is it absolutely necessary that it
> anticipate?

5pts.

In typical runs, the output activation for input 0_ is about .5, much
larger than the preceding output activation of about .2.  Thus, the
network does seem to anticipate the subsequent teacher activation.  It
need not necessarily do that in principle; in particular, a network
could learn the sequence 000100010001... .  However, if you try
explicit training on that sequence, you'll find that even then the
network anticipates the 1, but just not as much.  It seems that
error-reduction via backprop strongly encourages "anticipation."


> 1D. After training, "tall" the network several times, and plot the
> trajectory of the hidden node activations.  That is, let the x-axis
> be the activation of hidden node 1, the y-axis be the activation of
> hidden node 2, and plot the activations for each pattern, connecting
> the points with arrows.  Also, accurately plot the decision line
> made by the output node, and show how you derived the equation for
> that line.  HINT: The line is given by 
>      net^{out} = 0
>                =   w_{out,hid1} * act_{hid1} 
>                  + w_{out,hid2} * act_{hid2} 
>                  + bias^{out}.

10 pts.

After one particular training run, the hidden node activations showed
the following repeating cycle:

pat  act_{hid1}  act_{hid2}
---  ----------  ----------
00       .29        .68
0_       .40        .53
01       .52        .35
10       .20        .83

The output node had weights 4.14 and -5.28, and bias 1.15, so, using
the equation supplied above, the decision line is given by

act_{hid2} = .784 * act_{hid1} + .218

A graph of the trajectory and decision line then looks something like
this:

          1.0 +                                   ,'
              |                                 ,'
           .9 +                              ,''
              |       10                   ,'
           .8 +        ` trajectory      ,'
              |         `              ,'
           .7 +          00         ,'' decision
              |           `       ,'    line
           .6 +            `    ,'
 act_{hid2}   |             0_ '
           .5 +            ,  `
              |          ,'    `
           .4 +        ,'       `
              |      ,'           01
           .3 +   ,''
              | ,'
           .2 +'
              |
           .1 +
              |
           0  +---+---+---+---+---+---+---+---+---+---+
              0  .1  .2  .3  .4  .5  .6  .7  .8  .9  1.0

                             act_{hid1}

It's difficult to draw arrowheads in ASCII type, so I'll just say in
words that the trajectory cycles from top left to bottom right, and
repeats.  The positive (+1) side of the decision line is the lower
right.  You can see "anticipation" quite graphically: The 0_ pattern
lies closer to the +1 side of the decision line than the 00 pattern;
indeed, the 0_ pattern lies nearly on the decision line, yielding an
output activation of approximately 0.5, as mentioned earlier.

> 1E. Let the SRN dream: Set up a pattern file with all the input
> activations equal to zero; e.g., a pattern file with four
> repetitions of pattern 0_ from srn.pat (note that the teacher values
> are irrelevant for "tall"-ing).  Now "tall" the trained network
> (from 1D) several times (if you already quit the program after 1D,
> re-seed with the seed value you recorded, and retrain the network),
> and plot the trajectory as you did in 1D.  Why does the network
> stabilize instead of cycling as in 1D?  Why does the network in 1D
> cycle instead of stabilizing?  HINT: What is the role of the input
> activation?

5 pts.

          1.0 +                                   ,'
              |                                 ,'
           .9 +                              ,''
              |       *                    ,'
           .8 +        ` trajectory      ,'
              |         `              ,'
           .7 +           *         ,'' decision
              |           `       ,'    line
           .6 +            `    ,'
 act_{hid2}   |             `  '
           .5 +            ,  *
              |          ,'    `
           .4 +        ,'        `
              |      ,'            *
           .3 +   ,''               `
              | ,'                    `
           .2 +'                        *
              |                          `
           .1 +                             *
              |                               `***
           0  +---+---+---+---+---+---+---+---+---+---+
              0  .1  .2  .3  .4  .5  .6  .7  .8  .9  1.0

                             act_{hid1}

The "dreaming" network stabilizes with hidden node activations of
about .87 and .03 (for this particular run).  The reason is that the
weights between hidden nodes (i.e., from context to hidden) are
inhibitory, so that as one hidden node gets activated, it suppresses
the other hidden node (on the next time step).  In the present case,
hidden node 1 won the competition.  The only reason that the network
in part 1D didn't stabilize was because the occasional input "pulse"
reset the activations of the hidden nodes.  It's as if the hidden node
activations always run downhill to the bottom right of the graph, but
the input activation can pick it up and restart the trajectory.


> 2. An Oscillating Network.
> ...
> 2A. Let the network dream: Use the pattern file below and "tall" the
> network several times.  Write down the activations for at least 12
> updates.  Does the network oscillate or stabilize?

5 pts.

The hidden node activations go through the following cycle:
 
99 00 00
49 99 00
00 99 99
49 00 99
... and repeat! 


> 2B. Now change the weights in the network file so that "m" is -1.0 and
> "p" is 1.0 (instead of -10.0 and 10.0, respectively), and re-invoke
> the program.  "tall" the network several times.  Write down the
> activations for at least 12 updates.  Why does it stabilize instead of
> oscillate?

10 pts.

100   0   0
 50  73  26
 38  55  55
 50  45  54
 52  48  48
 50  50  49
 49  50  50
...
 50  50  50

Unlike part 2A, the weights for this network were not large enough to
fully activate the "next" node and fully suppress the "preceding"
node.  Because the net inputs were not large enough, the sigmoid
squashing function just squashed the activations until they were all
0.5.  That's a stable point because all the nodes then have a net
input of zero and an activation of 0.5.  (That would also be a stable
point for the network in part 2A, but the network can't get there from
where it starts.)


> 2C. Change the weights in the network file to small random values
> (e.g., %r 3 3 0 3).  Re-invoke the program, and "tall" the network
> several times.  Does the network oscillate or stabilize?  "newstart"
> the network with different random weights, "set state activation 3
> 1.0", and "tall" again.  Do that (newstart, set state act, and tall)
> five times.  For each network, report whether they stabilized or
> oscillated, their weights, and the activation values to which they
> stabilized or cycled through.  (For most random weight
> configurations, the network will stabilize.)  If you like, venture
> an explanation as to why random networks usually stabilize (but we
> won't get to that in class for several days yet, and there aren't
> any points for it).

5 pts.

I have never yet encountered a random network (with _small_ weights)
that didn't stabilize.  The stable activation values are typically
between .4 and .6 (near .5).  I'll show here just one example:
                                                                               
    prior-act
    47  51  51
                   current-act
   -31  20  -8     47
     3 -28  35     51
   -30  33   9     51
    weights

(Notice that the prior activations and current activations are indentical.)

Why do they stabilize instead of oscillate?  You can think of the
network as "really" having all zero weights, but with a little random
noise thrown into the weight values.  If the noise is small enough,
the behavior of the network won't be affected much.  A network with
all zero weights will stabilize at activations all 0.5, and our random
networks do nearly that.  (We'll learn later that any network with
_symmetrical_ connections will stabilize.  If we add a little random
noise to symmetrical networks, they remain stable.)

=== end ===
